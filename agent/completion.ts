import log from "encore.dev/log";
import { secret } from "encore.dev/config";
import { github, linear, memory, sandbox, tasks, ai, registry } from "~encore/clients";
import { savePhaseMetrics } from "./metrics";
import { completeJob } from "./db";
import { validateAgentScope } from "./helpers";
import type { AgentExecutionContext } from "./types";
import type { PhaseTracker } from "./metrics";

// --- Secrets ---

const RegistryExtractionEnabled = secret("RegistryExtractionEnabled");

// --- Types ---

export interface CompletionResult {
  success: boolean;
  prUrl?: string;
  filesChanged: string[];
  costUsd: number;
  tokensUsed: number;
}

export interface CompletionHelpers {
  report: (
    ctx: AgentExecutionContext,
    content: string,
    status: "working" | "completed" | "failed" | "needs_input",
    extra?: { prUrl?: string; filesChanged?: string[] }
  ) => Promise<void>;
  think: (ctx: AgentExecutionContext, thought: string) => Promise<void>;
  reportSteps: (
    ctx: AgentExecutionContext,
    phase: string,
    steps: Array<{ label: string; status: "active" | "done" | "error" | "info" }>,
    extra?: {
      title?: string;
      planProgress?: { current: number; total: number };
      tasks?: Array<{ id: string; title: string; status: string }>;
    }
  ) => Promise<void>;
  auditedStep: <T>(
    ctx: AgentExecutionContext,
    action: string,
    details: Record<string, unknown>,
    fn: () => Promise<T>
  ) => Promise<T>;
  audit: (opts: {
    sessionId: string;
    actionType: string;
    details: Record<string, unknown>;
    success: boolean;
    taskId?: string;
    repoName?: string;
    prUrl?: string;
  }) => Promise<void>;
  updateLinearIfExists: (ctx: AgentExecutionContext, msg: string, status: string) => Promise<void>;
}

/**
 * STEP 9-12: PR creation, Linear update, memory storage, sandbox cleanup.
 *
 * Called for the skipReview path (when AgentModular=true and options.skipReview=true).
 * In the future, approveReview() in review.ts can also call this instead of
 * duplicating the completion logic.
 */
export async function completeTask(
  ctx: AgentExecutionContext,
  completionData: {
    allFiles: Array<{ path: string; content: string; action: string }>;
    sandboxId: string;
    documentation: string;
    memoriesExtracted: string[];
    memoryStrings: string[];
  },
  tracker: PhaseTracker,
  helpers: CompletionHelpers,
): Promise<CompletionResult> {
  const { report, think, reportSteps, auditedStep, audit, updateLinearIfExists } = helpers;
  const { allFiles, sandboxId, documentation, memoriesExtracted } = completionData;

  tracker.start("completing");

  // === STEP 9: Create PR ===
  log.info("STEP 9: Creating PR");
  const branchName = `thefold/${ctx.taskId.toLowerCase().replace(/\s+/g, "-").substring(0, 60)}`;
  let prUrl = "";

  try {
    // Scope validation (ASI02): ensure PR targets the task's bound repo
    validateAgentScope(ctx, ctx.repoOwner, ctx.repoName);

    const pr = await auditedStep(ctx, "github_write", {
      operation: "createPR",
      owner: ctx.repoOwner,
      repo: ctx.repoName,
      branch: branchName,
    }, () => github.createPR({
      owner: ctx.repoOwner,
      repo: ctx.repoName,
      branch: branchName,
      title: `[TheFold] ${ctx.taskDescription.split("\n")[0].substring(0, 72)}`,
      body: documentation || "Auto-generated by TheFold",
      files: allFiles.map((f) => ({
        path: f.path,
        content: f.content,
        action: f.action as "create" | "modify" | "delete",
      })),
    }));
    prUrl = pr.url;
    log.info("STEP 9: PR created", { url: prUrl });
  } catch (e) {
    const msg = e instanceof Error ? e.message : String(e);
    if (msg.includes("403") || msg.includes("not accessible")) {
      log.warn("PR creation failed â€” permission denied", { repo: ctx.repoName, error: msg });
    } else {
      log.warn("PR creation failed", { repo: ctx.repoName, error: msg });
    }
    // Non-fatal â€” task still completes, user can create PR manually
  }

  await reportSteps(ctx, "Ferdig", [
    { label: "Kode validert", status: "done" },
    { label: prUrl ? "PR opprettet" : "PR feilet", status: prUrl ? "done" : "error" },
    { label: "Oppdaterer status", status: "active" },
  ], { title: prUrl ? "PR opprettet" : "Fullfort uten PR" });

  // === STEP 9.5: Registry auto-extraction (fire-and-forget) ===
  log.info("STEP 9.5: Registry auto-extraction");
  try {
    const enabled = RegistryExtractionEnabled();
    if (enabled === "true" && allFiles.length >= 2) {
      // Fire-and-forget â€” don't wait for extraction to complete
      extractAndRegisterComponents({
        repo: `${ctx.repoOwner}/${ctx.repoName}`,
        files: allFiles.map((f) => ({ path: f.path, content: f.content })),
        taskDescription: ctx.taskDescription,
      }).catch((err) => log.warn("registry extraction background error", { error: String(err) }));

      await report(ctx, "ðŸ” Analyserer kode for gjenbrukbare komponenter...", "working");
    }
  } catch (extractErr) {
    // Aldri la extraction feile hele completion
    log.warn("registry extraction setup failed", { error: String(extractErr) });
  }

  // === STEP 10: Update Linear + task status ===
  log.info("STEP 10: Updating Linear and task status");
  await updateLinearIfExists(
    ctx,
    `TheFold fullforte oppgaven.${prUrl ? ` PR: ${prUrl}` : ""}\n\n${documentation}`,
    "done"
  );

  if (ctx.thefoldTaskId) {
    try {
      await tasks.updateTaskStatus({
        id: ctx.thefoldTaskId,
        status: "done",
        prUrl: prUrl || undefined,
      });
    } catch (err) {
      log.warn("updateTaskStatus to done failed", { error: err instanceof Error ? err.message : String(err) });
    }
  }

  await audit({
    sessionId: ctx.conversationId,
    actionType: "task_completed",
    details: {
      filesChanged: allFiles.map((f) => f.path),
      prUrl,
      totalAttempts: ctx.totalAttempts,
    },
    success: true,
    taskId: ctx.taskId,
    repoName: `${ctx.repoOwner}/${ctx.repoName}`,
    prUrl,
  });

  // === STEP 11: Store memories (fire-and-forget) ===
  log.info("STEP 11: Storing memories", { count: memoriesExtracted.length });
  for (const mem of memoriesExtracted) {
    memory.store({
      content: mem,
      category: "decision",
      linearTaskId: ctx.taskId,
      memoryType: "decision",
      sourceRepo: `${ctx.repoOwner}/${ctx.repoName}`,
    }).catch((e) => log.warn("memory.store decision failed", { error: String(e) }));
  }

  // Store error patterns from attemptHistory
  for (const attempt of ctx.attemptHistory) {
    if (attempt.result === "failure" && attempt.error) {
      memory.store({
        content: `Error pattern in ${ctx.repoName}: ${attempt.error.substring(0, 500)}`,
        category: "error_pattern",
        linearTaskId: ctx.taskId,
        memoryType: "error_pattern",
        sourceRepo: `${ctx.repoOwner}/${ctx.repoName}`,
      }).catch((e) => log.warn("memory.store error_pattern failed", { error: String(e) }));
    }
  }

  // === STEP 11.5: Store procedural memory (YE) ===
  // Only store strategy when: first-attempt success + high quality
  if (ctx.totalAttempts === 1 && allFiles.length >= 2) {
    log.info("STEP 11.5: Storing procedural memory (strategy)");

    // YE: Detect task pattern and extract successful steps
    const taskPattern = detectTaskPattern(ctx.taskDescription, allFiles);
    const successfulSteps = extractSuccessfulSteps(
      ctx.attemptHistory.map((a, i) => ({
        attemptNumber: i + 1,
        result: a.result,
        error: a.error,
      }))
    );

    if (successfulSteps.length > 0) {
      const strategyContent = [
        `Task pattern: ${taskPattern}`,
        `Repository: ${ctx.repoOwner}/${ctx.repoName}`,
        `Task: ${ctx.taskDescription.substring(0, 300)}`,
        `Successful approach (${successfulSteps.length} steps):`,
        ...successfulSteps.map((step, i) => `${i + 1}. ${step}`),
        `Files changed: ${allFiles.map((f) => f.path).join(", ")}`,
      ].join("\n");

      memory.store({
        content: strategyContent,
        category: taskPattern,
        linearTaskId: ctx.taskId,
        memoryType: "strategy",
        sourceRepo: `${ctx.repoOwner}/${ctx.repoName}`,
        tags: [taskPattern, "first-attempt-success", "high-quality"],
      }).catch((e) => log.warn("memory.store strategy failed", { error: String(e) }));

      log.info("strategy memory stored", { pattern: taskPattern, steps: successfulSteps.length });
    }
  }

  // === STEP 12: Final report + sandbox cleanup ===
  log.info("STEP 12: Cleanup and final report");

  const completionMsg = [
    "Oppgave fullfort",
    prUrl ? `PR: ${prUrl}` : "",
    `Filer endret: ${allFiles.length}`,
    `Kostnad: $${ctx.totalCostUsd.toFixed(4)}`,
  ].filter(Boolean).join("\n");

  await report(ctx, completionMsg, "completed", {
    prUrl: prUrl || undefined,
    filesChanged: allFiles.map((f) => f.path),
  });

  await reportSteps(ctx, "Ferdig", [
    { label: "Kode skrevet", status: "done" },
    { label: "Validert", status: "done" },
    { label: prUrl ? "PR opprettet" : "Fullfort", status: "done" },
    { label: "Ferdig", status: "done" },
  ], { title: "Oppgave fullfort" });

  await think(ctx, `Oppgaven er fullfort. ${allFiles.length} filer endret.${prUrl ? ` PR: ${prUrl}` : ""}`);

  // Destroy sandbox (fire-and-forget â€” non-critical)
  sandbox.destroy({ sandboxId }).catch(() => { /* Sandbox may already be destroyed */ });

  // STEP 12.5: Stop MCP servers (fire-and-forget â€” non-critical)
  try {
    const { stopAllServers } = await import("../mcp/router");
    stopAllServers();
  } catch {
    // Non-critical
  }

  // Save phase metrics (non-critical)
  tracker.end();
  if (ctx.jobId) {
    try {
      await savePhaseMetrics(ctx.jobId, ctx.taskId, tracker.getAll());
    } catch (err) {
      log.warn("savePhaseMetrics failed", { error: err instanceof Error ? err.message : String(err) });
    }
    await completeJob(ctx.jobId).catch((err) => log.warn("completeJob failed", { error: err instanceof Error ? err.message : String(err) }));
  }

  return {
    success: true,
    prUrl: prUrl || undefined,
    filesChanged: allFiles.map((f) => f.path),
    costUsd: ctx.totalCostUsd,
    tokensUsed: ctx.totalTokensUsed,
  };
}

// --- Helper: Procedural memory (YE) ---

/**
 * YE: Detect task pattern from description and files.
 * Returns category for strategy classification.
 */
export function detectTaskPattern(
  taskDescription: string,
  files: Array<{ path: string; content: string; action: string }>,
): string {
  const desc = taskDescription.toLowerCase();
  const paths = files.map((f) => f.path.toLowerCase()).join(" ");

  // Heuristikk-basert kategorisering
  if (desc.includes("migrat") || paths.includes("migration") || paths.includes(".up.sql")) {
    return "database_migration";
  }
  if (desc.includes("api") && (desc.includes("endpoint") || desc.includes("route"))) {
    return "api_endpoint";
  }
  if (
    desc.includes("component") || desc.includes("ui") || desc.includes("frontend")
    || paths.includes("/components/") || paths.includes(".tsx")
  ) {
    return "frontend_component";
  }
  if (desc.includes("bug") || desc.includes("fix") || desc.includes("error")) {
    return "bug_fix";
  }
  if (desc.includes("refactor") || desc.includes("clean") || desc.includes("improve")) {
    return "refactoring";
  }
  if (desc.includes("test") || paths.includes(".test.") || paths.includes(".spec.")) {
    return "testing";
  }
  if (desc.includes("security") || desc.includes("auth") || desc.includes("permission")) {
    return "security";
  }
  if (desc.includes("performance") || desc.includes("optimize") || desc.includes("speed")) {
    return "performance";
  }
  if (desc.includes("integrat") || desc.includes("connect") || desc.includes("webhook")) {
    return "integration";
  }
  return "other";
}

/**
 * YE: Extract successful steps from attempt history.
 * Only includes steps that worked (based on first successful attempt).
 */
export function extractSuccessfulSteps(
  attemptHistory: Array<{
    attemptNumber: number;
    result: "success" | "failure";
    error?: string;
    plan?: { steps: Array<{ title: string; description: string }> };
  }>,
): string[] {
  // Find first successful attempt
  const successfulAttempt = attemptHistory.find((a) => a.result === "success");
  if (!successfulAttempt || !successfulAttempt.plan) {
    return [];
  }

  // Extract step titles from successful plan
  return successfulAttempt.plan.steps.map((s) => s.title);
}

// --- Helper: Extract and register components ---

/**
 * Extract and register components (fire-and-forget helper for STEP 9.5).
 * Calls ai.callForExtraction and registry.register for each component.
 */
async function extractAndRegisterComponents(params: {
  repo: string;
  files: Array<{ path: string; content: string }>;
  taskDescription: string;
}): Promise<number> {
  // Filtrer bort test-filer og config-filer
  const candidateFiles = params.files.filter((f) =>
    !f.path.includes(".test.") &&
    !f.path.includes(".spec.") &&
    !f.path.includes("node_modules") &&
    !f.path.endsWith(".json") &&
    !f.path.endsWith(".md") &&
    !f.path.endsWith(".lock") &&
    f.content.length > 100
  );

  if (candidateFiles.length < 2) {
    log.info("too few candidate files for extraction", { count: candidateFiles.length });
    return 0;
  }

  // Kall AI for extraction
  const filesSummary = candidateFiles.map((f) => ({
    path: f.path,
    content: f.content.substring(0, 2000), // Begrens til 2000 tegn per fil
    lines: f.content.split("\n").length,
  }));

  const response = await ai.callForExtraction({
    task: params.taskDescription,
    repo: params.repo,
    files: filesSummary,
  });

  // Registrer hver komponent
  let registered = 0;
  for (const comp of response.components) {
    if (!comp.name || !comp.files || comp.files.length === 0 || comp.qualityScore < 50) {
      continue; // Skip invalid components
    }

    try {
      // Berik med full filinnhold
      const enrichedFiles = comp.files.map((cf) => {
        const original = params.files.find((f) => f.path === cf.path);
        return {
          path: cf.path,
          content: original?.content || cf.content,
          language: detectLanguage(cf.path),
        };
      });

      await registry.register({
        name: comp.name,
        description: comp.description,
        category: comp.category as any,
        files: enrichedFiles,
        entryPoint: comp.entryPoint,
        dependencies: comp.dependencies || [],
        sourceRepo: params.repo,
        tags: comp.tags || [],
        version: "1.0.0",
      });

      registered++;
      log.info("auto-registered component", { name: comp.name, repo: params.repo });
    } catch (regErr) {
      // Duplikat-navn etc. â€” logg og fortsett
      log.warn("auto-register failed", { name: comp.name, error: String(regErr) });
    }
  }

  log.info("extraction completed", { repo: params.repo, registered, total: response.components.length });
  return registered;
}

function detectLanguage(path: string): string {
  if (path.endsWith(".ts") || path.endsWith(".tsx")) return "typescript";
  if (path.endsWith(".js") || path.endsWith(".jsx")) return "javascript";
  if (path.endsWith(".css")) return "css";
  if (path.endsWith(".sql")) return "sql";
  if (path.endsWith(".html")) return "html";
  return "unknown";
}
